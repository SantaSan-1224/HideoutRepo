# アーカイブシステム要件定義書

## 1. システム概要

### 1.1 目的
企業内のファイルサーバ（FSx for Windows File Server）上のファイルを、ユーザーの依頼に基づいてAWS S3（Glacier Deep Archive）にアーカイブし、履歴管理・復元機能を提供するシステム。

### 1.2 システム構成
- **依頼受付**: FASTワークフローシステム
- **処理サーバ**: AWS EC2（4vCPU、16GBメモリ）
- **ファイルサーバ**: FSx for Windows File Server（Windows環境）
- **アーカイブ先**: AWS S3（Glacier Deep Archive）
- **データベース**: PostgreSQL
- **Webアプリケーション**: Streamlit

## 2. 運用フロー

### 2.1 アーカイブ処理フロー
1. **依頼受付**
   - ユーザーがFASTでアーカイブ依頼を提出
   - アーカイブ対象ディレクトリを記載したCSVファイルをアップロード
   - 承認ワークフローが実行される

2. **アーカイブ処理**
   - 運用者が承認後、アーカイブツール（Python）を実行
   - CSVファイルを読み込み、対象ディレクトリの妥当性チェック
   - ファイルをS3（Glacier Deep Archive）に直接転送
   - 元ファイルを削除し、空ファイル（`元ファイル名_archived.txt`）を作成
   - 処理結果をPostgreSQLに記録

3. **履歴管理**
   - Streamlitアプリでアーカイブ履歴を閲覧・検索可能
   - 永続的に履歴を保存

### 2.2 復元処理フロー
1. **復元依頼**
   - ユーザーがFASTで復元依頼を提出
   - 復元対象を記載したCSVファイルをアップロード
   - 承認ワークフローが実行される

2. **復元処理**
   - 運用者が承認後、復元ツール（Python）を実行
   - S3に復元リクエストを送信
   - 復元完了後、指定されたディレクトリにファイルをコピー
   - 同名ファイルが存在する場合はチェック処理
   - `_archived`ファイルは削除しない（アーカイブ済み証跡として残す）

## 3. 技術仕様

### 3.1 開発言語・技術
- **アーカイブ/復元スクリプト**: Python
- **AWS連携**: AWS CLI、boto3
- **データベース**: PostgreSQL
- **Webアプリケーション**: Streamlit
- **ファイル転送**: VPCエンドポイント経由

### 3.2 CSVファイル仕様
- **アーカイブ依頼**: ディレクトリパスのみ
- **復元依頼**: 復元対象パス、復元先ディレクトリ

### 3.3 データベース設計
- **依頼情報テーブル**: 依頼ID、依頼者、依頼日時、承認日時、処理状況
- **アーカイブ詳細テーブル**: 依頼ID、元ファイルパス、S3パス、アーカイブ日時、ファイルサイズ、処理結果

### 3.4 S3設定
- **ストレージクラス**: Glacier Deep Archive（直接転送）
- **転送方式**: 個別ファイル転送（圧縮なし）
- **接続**: VPCエンドポイント経由

## 4. エラーハンドリング・ログ

### 4.1 エラー処理
- **処理中断時**: ツール終了、未処理・エラー項目を別CSVに出力
- **エラーCSV出力先**: 元CSVと同じ場所
- **エラーファイル命名**: 再試行を考慮した命名規則（要詳細検討）

### 4.2 ログレベル
- **ERROR**: 転送エラー、パス存在チェックエラー
- **INFO**: その他の処理情報

### 4.3 想定エラー
- ネットワーク障害（FSx、S3接続エラー）
- 権限エラー（ファイルアクセス権限、AWS IAM権限）
- 容量不足（一時作業領域）
- ファイルロック（他プロセスによる使用中）
- AWS API制限（S3 API制限）

## 5. 設定管理

### 5.1 設定ファイル化対象
- VPCエンドポイントDNS名
- アーカイブ後ファイル命名規則（`_archived`サフィックス）

### 5.2 システム設定
- **IAM認証**: サーバ側でIAMユーザプロファイル設定
- **PostgreSQL接続**: ハードコード

## 6. 運用規模・想定

### 6.1 処理規模
- **月間依頼件数**: 100-200件
- **月間処理ファイル数**: 10,000-20,000ファイル
- **運用体制**: 2人1組での作業、並行処理なし

### 6.2 非機能要件
- **バックアップ・冗長化**: 不要
- **監視・ヘルスチェック**: 不要
- **進捗確認機能**: あれば良い程度
- **パフォーマンス**: 考慮しない
- **並行処理**: 現時点では実装しない

## 7. 制約事項

### 7.1 認証・権限
- **アクセス権限**: 運用管理者のみ
- **依頼者権限**: 企業社員番号7桁、部署ごとに独立したファイルサーバ
- **閲覧制御**: 特に設けない

### 7.2 データ保存
- **アーカイブ履歴**: 永続保存
- **復元履歴**: 記録しない
- **ファイルサイズ制限**: なし

### 7.3 運用制約
- **通知機能**: 導入しない（大量通知を懸念）
- **リソース競合**: 考慮しない（業務停止は稀）

## 8. 今後の開発ステップ

### 8.1 開発優先順位
1. **アーカイブスクリプト**: CSV読み込み、S3アップロード、空ファイル作成
2. **データベース設計・構築**: PostgreSQL、テーブル作成
3. **Streamlitアプリ**: 履歴閲覧機能
4. **復元スクリプト**: S3復元、ファイルコピー

### 8.2 未確定事項
- **エラーファイル命名規則**: 再試行を考慮した詳細仕様
- **DBコミット方式**: ディレクトリ単位 vs 一括コミット（負荷を考慮して決定）
- **進捗確認機能**: 実装レベルの詳細仕様