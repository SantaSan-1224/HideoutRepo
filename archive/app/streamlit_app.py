#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´é–²è¦§ Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
"""

import streamlit as st
import pandas as pd
import psycopg2
import json
import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import io
import base64
from sqlalchemy import create_engine
import warnings

# Pandasè­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=UserWarning, module='pandas')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-metric {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
    }
    .error-metric {
        background-color: #f8d7da;
        border-left: 4px solid #dc3545;
    }
    .info-metric {
        background-color: #d1ecf1;
        border-left: 4px solid #17a2b8;
    }
    .stDataFrame {
        border: 1px solid #e0e0e0;
        border-radius: 0.25rem;
    }
    .reset-button {
        background-color: #6c757d;
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 0.25rem;
        cursor: pointer;
    }
    .reset-button:hover {
        background-color: #545b62;
    }
</style>
""", unsafe_allow_html=True)

class ArchiveHistoryApp:
    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´ç®¡ç†ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        self.config = self.load_config()
        self.engine = None
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if 'search_executed' not in st.session_state:
            st.session_state.search_executed = False
        if 'last_search_params' not in st.session_state:
            st.session_state.last_search_params = {}
        if 'search_results' not in st.session_state:
            st.session_state.search_results = pd.DataFrame()
        if 'search_stats' not in st.session_state:
            st.session_state.search_stats = {}
        
    def load_config(self) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        config_path = "config/archive_config.json"
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        except FileNotFoundError:
            st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
            st.error("config/archive_config.jsonã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        except json.JSONDecodeError as e:
            st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
            st.stop()
    
    def get_database_engine(self):
        """SQLAlchemy ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—ï¼ˆpandasè­¦å‘Šå¯¾ç­–ï¼‰"""
        if self.engine is None:
            try:
                db_config = self.config.get('database', {})
                
                # PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ã®æ§‹ç¯‰
                connection_string = (
                    f"postgresql://{db_config.get('user', 'postgres')}:"
                    f"{db_config.get('password', '')}@"
                    f"{db_config.get('host', 'localhost')}:"
                    f"{db_config.get('port', 5432)}/"
                    f"{db_config.get('database', 'archive_system')}"
                )
                
                self.engine = create_engine(connection_string)
                
                # æ¥ç¶šãƒ†ã‚¹ãƒˆ
                with self.engine.connect() as conn:
                    conn.execute("SELECT 1")
                
                return self.engine
                
            except ImportError:
                st.error("SQLAlchemyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install sqlalchemy ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            except Exception as e:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.stop()
        return self.engine
    
    def search_archive_history(self, 
                             start_date: datetime.date,
                             end_date: datetime.date,
                             request_id: str = "",
                             requester: str = "",
                             file_path: str = "",
                             limit: int = 1000,
                             offset: int = 0) -> pd.DataFrame:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´æ¤œç´¢"""
        try:
            engine = self.get_database_engine()
            
            # åŸºæœ¬ã‚¯ã‚¨ãƒª
            query = """
                SELECT 
                    id,
                    request_id,
                    requester,
                    request_date,
                    original_file_path,
                    s3_path,
                    archive_date,
                    file_size,
                    created_at
                FROM archive_history 
                WHERE request_date::date BETWEEN %(start_date)s AND %(end_date)s
            """
            params = {'start_date': start_date, 'end_date': end_date}
            
            # ä¾é ¼IDãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if request_id.strip():
                query += " AND request_id ILIKE %(request_id)s"
                params['request_id'] = f"%{request_id.strip()}%"
            
            # ä¾é ¼è€…ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if requester.strip():
                query += " AND requester LIKE %(requester)s"
                params['requester'] = f"%{requester.strip()}%"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if file_path.strip():
                query += " AND original_file_path ILIKE %(file_path)s"
                params['file_path'] = f"%{file_path.strip()}%"
            
            # ã‚½ãƒ¼ãƒˆãƒ»åˆ¶é™
            query += " ORDER BY request_date DESC LIMIT %(limit)s OFFSET %(offset)s"
            params.update({'limit': limit, 'offset': offset})
            
            # å®Ÿè¡Œï¼ˆSQLAlchemy engineä½¿ç”¨ã§pandasè­¦å‘Šå›é¿ï¼‰
            df = pd.read_sql_query(query, engine, params=params)
            
            if not df.empty:
                # æ—¥æ™‚åˆ—ã®å¤‰æ›
                df['request_date'] = pd.to_datetime(df['request_date'])
                df['archive_date'] = pd.to_datetime(df['archive_date'])
                df['created_at'] = pd.to_datetime(df['created_at'])
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®è¡¨ç¤ºå½¢å¼å¤‰æ›
                df['file_size_mb'] = (df['file_size'] / 1024 / 1024).round(2)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®çŸ­ç¸®è¡¨ç¤ºç”¨
                df['file_path_short'] = df['original_file_path'].apply(
                    lambda x: x if len(x) <= 50 else f"{x[:47]}..."
                )
            
            return df
            
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def get_statistics(self, 
                      start_date: datetime.date,
                      end_date: datetime.date,
                      request_id: str = "",
                      requester: str = "",
                      file_path: str = "") -> Dict:
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        try:
            engine = self.get_database_engine()
            
            # åŸºæœ¬ã‚¯ã‚¨ãƒª
            query = """
                SELECT 
                    COUNT(*) as total_files,
                    SUM(file_size) as total_size,
                    COUNT(DISTINCT request_id) as total_requests,
                    AVG(file_size) as avg_file_size,
                    MAX(file_size) as max_file_size,
                    MIN(request_date) as first_archive,
                    MAX(request_date) as last_archive
                FROM archive_history 
                WHERE request_date::date BETWEEN %(start_date)s AND %(end_date)s
            """
            params = {'start_date': start_date, 'end_date': end_date}
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶è¿½åŠ 
            if request_id.strip():
                query += " AND request_id ILIKE %(request_id)s"
                params['request_id'] = f"%{request_id.strip()}%"
                
            if requester.strip():
                query += " AND requester LIKE %(requester)s"
                params['requester'] = f"%{requester.strip()}%"
            
            if file_path.strip():
                query += " AND original_file_path ILIKE %(file_path)s"
                params['file_path'] = f"%{file_path.strip()}%"
            
            # å®Ÿè¡Œ
            with engine.connect() as conn:
                result = conn.execute(query, params).fetchone()
                
                if result:
                    return {
                        'total_files': result[0] or 0,
                        'total_size': result[1] or 0,
                        'total_requests': result[2] or 0,
                        'avg_file_size': result[3] or 0,
                        'max_file_size': result[4] or 0,
                        'first_archive': result[5],
                        'last_archive': result[6]
                    }
                else:
                    return {
                        'total_files': 0,
                        'total_size': 0,
                        'total_requests': 0,
                        'avg_file_size': 0,
                        'max_file_size': 0,
                        'first_archive': None,
                        'last_archive': None
                    }
                    
        except Exception as e:
            st.error(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    def get_requester_list(self) -> List[str]:
        """ä¾é ¼è€…ãƒªã‚¹ãƒˆå–å¾—"""
        try:
            engine = self.get_database_engine()
            query = "SELECT DISTINCT requester FROM archive_history ORDER BY requester"
            
            with engine.connect() as conn:
                result = conn.execute(query)
                return [row[0] for row in result]
                
        except Exception as e:
            st.error(f"ä¾é ¼è€…ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def format_file_size(self, size_bytes: int) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if size_bytes == 0:
            return "0 B"
        
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = 0
        size = float(size_bytes)
        
        while size >= 1024.0 and i < len(size_names) - 1:
            size /= 1024.0
            i += 1
        
        return f"{size:.1f} {size_names[i]}"
    
    def create_download_link(self, df: pd.DataFrame, filename: str, file_format: str = "excel") -> str:
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ä½œæˆ"""
        try:
            if file_format == "excel":
                # Excelå½¢å¼
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # è¡¨ç¤ºç”¨ã®DataFrameã‚’ä½œæˆ
                    export_df = df.copy()
                    
                    # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
                    column_mapping = {
                        'id': 'ID',
                        'request_id': 'ä¾é ¼ID',
                        'requester': 'ä¾é ¼è€…',
                        'request_date': 'ä¾é ¼æ—¥æ™‚',
                        'original_file_path': 'å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹',
                        's3_path': 'S3ãƒ‘ã‚¹',
                        'archive_date': 'ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ—¥æ™‚',
                        'file_size': 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(Bytes)',
                        'file_size_mb': 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º(MB)',
                        'created_at': 'ä½œæˆæ—¥æ™‚'
                    }
                    
                    # ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
                    export_df = export_df.drop(['file_path_short'], axis=1, errors='ignore')
                    
                    # åˆ—åå¤‰æ›´
                    export_df = export_df.rename(columns=column_mapping)
                    
                    # Excelã«æ›¸ãè¾¼ã¿
                    export_df.to_excel(writer, sheet_name='ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´', index=False)
                
                output.seek(0)
                b64 = base64.b64encode(output.read()).decode()
                
            elif file_format == "csv":
                # CSVå½¢å¼
                export_df = df.copy()
                export_df = export_df.drop(['file_path_short'], axis=1, errors='ignore')
                
                csv_buffer = io.StringIO()
                export_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                csv_string = csv_buffer.getvalue()
                b64 = base64.b64encode(csv_string.encode('utf-8-sig')).decode()
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ä½œæˆ
            mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" if file_format == "excel" else "text/csv"
            
            href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}">ğŸ“¥ {filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
            return href
            
        except Exception as e:
            st.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return ""
    
    def render_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼æç”»"""
        st.markdown('<h1 class="main-header">ğŸ“ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ </h1>', unsafe_allow_html=True)
        
        # ç¾åœ¨æ™‚åˆ»è¡¨ç¤º
        current_time = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        st.markdown(f"<div style='text-align: center; color: #666; margin-bottom: 2rem;'>æœ€çµ‚æ›´æ–°: {current_time}</div>", 
                   unsafe_allow_html=True)
        
        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼ˆæ¤œç´¢å®Ÿè¡Œå¾Œã«è¡¨ç¤ºï¼‰
        if st.session_state.search_executed:
            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button("ğŸ”„ åˆæœŸç”»é¢ã«æˆ»ã‚‹", key="reset_button", help="æ¤œç´¢çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¦åˆæœŸç”»é¢ã«æˆ»ã‚Šã¾ã™"):
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.search_executed = False
                    st.session_state.search_results = pd.DataFrame()
                    st.session_state.search_stats = {}
                    st.session_state.last_search_params = {}
                    st.experimental_rerun()
    
    def render_sidebar_filters(self):
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æç”»"""
        st.sidebar.header("ğŸ” æ¤œç´¢æ¡ä»¶")
        
        # æ—¥ä»˜ç¯„å›²
        st.sidebar.subheader("æœŸé–“æŒ‡å®š")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ—¥ä»˜ï¼ˆéå»30æ—¥ï¼‰
        end_date = datetime.date.today()
        start_date = end_date - datetime.timedelta(days=30)
        
        start_date = st.sidebar.date_input(
            "é–‹å§‹æ—¥",
            value=start_date,
            max_value=end_date,
            key="start_date"
        )
        
        end_date = st.sidebar.date_input(
            "çµ‚äº†æ—¥", 
            value=end_date,
            min_value=start_date,
            key="end_date"
        )
        
        # ä¾é ¼IDæ¤œç´¢
        st.sidebar.subheader("ä¾é ¼ID")
        request_id = st.sidebar.text_input(
            "ä¾é ¼IDï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰",
            placeholder="ä¾‹: REQ-2025-001",
            key="request_id"
        )
        
        # ä¾é ¼è€…ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        st.sidebar.subheader("ä¾é ¼è€…")
        requester_list = self.get_requester_list()
        
        if requester_list:
            selected_requester = st.sidebar.selectbox(
                "ä¾é ¼è€…é¸æŠ",
                options=[""] + requester_list,
                index=0,
                key="requester_select"
            )
        else:
            selected_requester = st.sidebar.text_input(
                "ä¾é ¼è€…ï¼ˆç¤¾å“¡ç•ªå·ï¼‰",
                key="requester_text"
            )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ¤œç´¢
        st.sidebar.subheader("ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢")
        file_path = st.sidebar.text_input(
            "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰",
            placeholder="ä¾‹: project1, .txt, \\\\server\\share",
            key="file_path"
        )
        
        # è¡¨ç¤ºä»¶æ•°
        st.sidebar.subheader("è¡¨ç¤ºè¨­å®š")
        limit = st.sidebar.selectbox(
            "è¡¨ç¤ºä»¶æ•°",
            options=[100, 500, 1000, 2000],
            index=2,
            key="limit"
        )
        
        return start_date, end_date, request_id, selected_requester, file_path, limit
    
    def render_statistics(self, stats: Dict):
        """çµ±è¨ˆæƒ…å ±æç”»"""
        if not stats:
            return
            
        st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆ3åˆ—ï¼‰
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown('<div class="metric-container success-metric">', unsafe_allow_html=True)
            st.metric(
                label="ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°",
                value=f"{stats['total_files']:,}",
                help="æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°"
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="metric-container info-metric">', unsafe_allow_html=True)
            st.metric(
                label="ç·ã‚µã‚¤ã‚º",
                value=self.format_file_size(stats['total_size']),
                help="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆè¨ˆã‚µã‚¤ã‚º"
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="metric-container success-metric">', unsafe_allow_html=True)
            st.metric(
                label="ä¾é ¼ä»¶æ•°",
                value=f"{stats['total_requests']:,}",
                help="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¾é ¼ã®ç·æ•°"
            )
            st.markdown('</div>', unsafe_allow_html=True)
        
        # è©³ç´°çµ±è¨ˆæƒ…å ±
        if stats['avg_file_size'] > 0:
            st.markdown("### ğŸ“ˆ è©³ç´°çµ±è¨ˆ")
            
            detail_col1, detail_col2 = st.columns(2)
            
            with detail_col1:
                st.write("**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºçµ±è¨ˆ**")
                st.write(f"- å¹³å‡ã‚µã‚¤ã‚º: {self.format_file_size(stats['avg_file_size'])}")
                st.write(f"- æœ€å¤§ã‚µã‚¤ã‚º: {self.format_file_size(stats['max_file_size'])}")
            
            with detail_col2:
                if stats['first_archive'] and stats['last_archive']:
                    st.write("**æœŸé–“æƒ…å ±**")
                    st.write(f"- æœ€åˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {stats['first_archive'].strftime('%Y-%m-%d %H:%M')}")
                    st.write(f"- æœ€æ–°ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {stats['last_archive'].strftime('%Y-%m-%d %H:%M')}")
    
    def render_data_table(self, df: pd.DataFrame):
        """ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«æç”»"""
        if df.empty:
            st.warning("ğŸ“­ æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.info("ğŸ’¡ æ¤œç´¢æ¡ä»¶ã‚’å¤‰æ›´ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            return
        
        st.subheader(f"ğŸ“‹ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´ ({len(df):,}ä»¶)")
        
        # è¡¨ç¤ºç”¨ã®DataFrameã‚’æº–å‚™
        display_df = df.copy()
        
        # è¡¨ç¤ºåˆ—ã®é¸æŠ
        display_columns = {
            'request_id': 'ä¾é ¼ID',
            'requester': 'ä¾é ¼è€…',
            'request_date': 'ä¾é ¼æ—¥æ™‚',
            'file_path_short': 'ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹',
            'file_size_mb': 'ã‚µã‚¤ã‚º(MB)',
            'archive_date': 'ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ—¥æ™‚'
        }
        
        # åˆ—ã‚’é¸æŠãƒ»ãƒªãƒãƒ¼ãƒ 
        display_df = display_df[list(display_columns.keys())]
        display_df = display_df.rename(columns=display_columns)
        
        # æ—¥æ™‚åˆ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        display_df['ä¾é ¼æ—¥æ™‚'] = display_df['ä¾é ¼æ—¥æ™‚'].dt.strftime('%Y-%m-%d %H:%M')
        display_df['ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ—¥æ™‚'] = display_df['ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ—¥æ™‚'].dt.strftime('%Y-%m-%d %H:%M')
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )
        
        # è©³ç´°è¡¨ç¤ºã®å±•é–‹å¯èƒ½ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        with st.expander("ğŸ” è©³ç´°æƒ…å ±è¡¨ç¤º"):
            selected_indices = st.multiselect(
                "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠï¼ˆä¾é ¼IDã§é¸æŠï¼‰",
                options=df['request_id'].unique(),
                max_selections=5,
                key="detail_select"
            )
            
            if selected_indices:
                detail_df = df[df['request_id'].isin(selected_indices)]
                
                for _, row in detail_df.iterrows():
                    st.markdown(f"**ä¾é ¼ID: {row['request_id']}**")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"- **ä¾é ¼è€…**: {row['requester']}")
                        st.write(f"- **ä¾é ¼æ—¥æ™‚**: {row['request_date'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.write(f"- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {self.format_file_size(row['file_size'])}")
                    
                    with col2:
                        st.write(f"- **ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ—¥æ™‚**: {row['archive_date'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.write(f"- **å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `{row['original_file_path']}`")
                        st.write(f"- **S3ãƒ‘ã‚¹**: `{row['s3_path']}`")
                    
                    st.markdown("---")
    
    def render_export_section(self, df: pd.DataFrame):
        """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³æç”»"""
        if df.empty:
            return
            
        st.subheader("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        col1, col2 = st.columns(2)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        with col1:
            st.markdown("**Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
            excel_filename = f"archive_history_{timestamp}.xlsx"
            excel_link = self.create_download_link(df, excel_filename, "excel")
            if excel_link:
                st.markdown(excel_link, unsafe_allow_html=True)
                st.caption("Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.xlsxï¼‰å½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        with col2:
            st.markdown("**CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
            csv_filename = f"archive_history_{timestamp}.csv"
            csv_link = self.create_download_link(df, csv_filename, "csv")
            if csv_link:
                st.markdown(csv_link, unsafe_allow_html=True)
                st.caption("CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆUTF-8-SIGï¼‰å½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    def render_initial_screen(self):
        """åˆæœŸç”»é¢ã®æç”»"""
        st.info("ğŸ” **æ¤œç´¢æ¡ä»¶ã‚’è¨­å®šã—ã¦ã€Œæ¤œç´¢å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„**")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ“‹ ä½¿ç”¨æ–¹æ³•")
            st.markdown("""
            1. **æœŸé–“æŒ‡å®š**: æ¤œç´¢ã—ãŸã„æœŸé–“ã‚’é¸æŠ
            2. **ä¾é ¼ID**: ç‰¹å®šã®ä¾é ¼IDã§çµã‚Šè¾¼ã¿ï¼ˆä»»æ„ï¼‰
            3. **ä¾é ¼è€…**: ç¤¾å“¡ç•ªå·ã§çµã‚Šè¾¼ã¿ï¼ˆä»»æ„ï¼‰
            4. **ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã§çµã‚Šè¾¼ã¿ï¼ˆä»»æ„ï¼‰
            5. **æ¤œç´¢å®Ÿè¡Œ**: ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦æ¤œç´¢é–‹å§‹
            """)
        
        with col2:
            st.markdown("### âš¡ æ©Ÿèƒ½ä¸€è¦§")
            st.markdown("""
            - ğŸ“Š **çµ±è¨ˆæƒ…å ±è¡¨ç¤º**: ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒ»ã‚µã‚¤ã‚ºãƒ»ä¾é ¼ä»¶æ•°
            - ğŸ” **è©³ç´°æ¤œç´¢**: è¤‡æ•°æ¡ä»¶ã§ã®çµã‚Šè¾¼ã¿æ¤œç´¢
            - ğŸ“¥ **ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: Excelãƒ»CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            - ğŸ”„ **åˆæœŸç”»é¢ãƒªã‚»ãƒƒãƒˆ**: ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§æ¤œç´¢æ¡ä»¶ã‚¯ãƒªã‚¢
            """)
        
        st.markdown("### âš ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«ã¤ã„ã¦")
        st.warning("æ¤œç´¢å®Ÿè¡Œå‰ã¯ãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¸è¦ãªæƒ…å ±ã®æ¼æ´©ã‚’é˜²ã„ã§ã„ã¾ã™ã€‚")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçŠ¶æ…‹ç¢ºèª
        try:
            engine = self.get_database_engine()
            with engine.connect() as conn:
                conn.execute("SELECT COUNT(*) FROM archive_history")
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: æ­£å¸¸")
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: ã‚¨ãƒ©ãƒ¼ - {str(e)}")
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        try:
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            self.render_header()
            
            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            start_date, end_date, request_id, requester, file_path, limit = self.render_sidebar_filters()
            
            # æ¤œç´¢å®Ÿè¡Œãƒœã‚¿ãƒ³
            search_button = st.sidebar.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary", key="search_button")
            
            # æ¤œç´¢å®Ÿè¡Œã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœè¡¨ç¤º
            if search_button:
                # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
                current_params = {
                    'start_date': start_date,
                    'end_date': end_date,
                    'request_id': request_id,
                    'requester': requester,
                    'file_path': file_path,
                    'limit': limit
                }
                
                # æ¤œç´¢å®Ÿè¡Œ
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ä¸­..."):
                    df = self.search_archive_history(
                        start_date=start_date,
                        end_date=end_date,
                        request_id=request_id,
                        requester=requester,
                        file_path=file_path,
                        limit=limit
                    )
                    
                    stats = self.get_statistics(
                        start_date=start_date,
                        end_date=end_date,
                        request_id=request_id,
                        requester=requester,
                        file_path=file_path
                    )
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹æ›´æ–°
                st.session_state.search_executed = True
                st.session_state.search_results = df
                st.session_state.search_stats = stats
                st.session_state.last_search_params = current_params
                
                st.experimental_rerun()
            
            # çµæœè¡¨ç¤ºï¼ˆæ¤œç´¢å®Ÿè¡Œå¾Œã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹å ´åˆï¼‰
            if st.session_state.search_executed:
                if not st.session_state.search_results.empty:
                    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                    self.render_statistics(st.session_state.search_stats)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
                    self.render_data_table(st.session_state.search_results)
                    
                    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
                    self.render_export_section(st.session_state.search_results)
                    
                else:
                    # æ¤œç´¢çµæœãŒç©ºã®å ´åˆ
                    st.warning("ğŸ“­ æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    st.info("ğŸ’¡ æ¤œç´¢æ¡ä»¶ã‚’å¤‰æ›´ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    
                    # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨ç¤º
                    if st.session_state.last_search_params:
                        with st.expander("ğŸ” å®Ÿè¡Œã—ãŸæ¤œç´¢æ¡ä»¶"):
                            params = st.session_state.last_search_params
                            st.write(f"- **æœŸé–“**: {params['start_date']} ï½ {params['end_date']}")
                            if params['request_id']:
                                st.write(f"- **ä¾é ¼ID**: {params['request_id']}")
                            if params['requester']:
                                st.write(f"- **ä¾é ¼è€…**: {params['requester']}")
                            if params['file_path']:
                                st.write(f"- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: {params['file_path']}")
                            st.write(f"- **è¡¨ç¤ºä»¶æ•°**: {params['limit']}")
            else:
                # åˆæœŸç”»é¢è¡¨ç¤º
                self.render_initial_screen()
            
            # ãƒ•ãƒƒã‚¿ãƒ¼
            st.markdown("---")
            footer_text = "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  v1.0"
            if st.session_state.search_executed and st.session_state.last_search_params:
                params = st.session_state.last_search_params
                footer_text += f" | æ¤œç´¢æœŸé–“: {params['start_date']} ï½ {params['end_date']}"
            
            st.markdown(
                f"<div style='text-align: center; color: #666; font-size: 0.8rem;'>{footer_text}</div>",
                unsafe_allow_html=True
            )
            
        except Exception as e:
            st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.exception(e)
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if st.button("ğŸ”„ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ", key="error_reset"):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.experimental_rerun()

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    app = ArchiveHistoryApp()
    app.run()

if __name__ == "__main__":
    main()